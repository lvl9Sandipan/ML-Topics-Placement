# ML-Topics-Placement

# Supervised Learning
## $$ Regression
### ---> Linear Regression
### ---> Ridge and Lasso Regression
### ---> Polynomial Regression
### ---> Support Vector Regression

## Classification
### $$ Logistic Regression
### $$ [Support Vector Machines](https://medium.com/@kushaldps1996/a-complete-guide-to-support-vector-machines-svms-501e71aec19e)
#### ----> [SVM - Duality](https://youtu.be/6-ntMIaJpm0?si=MSeQdyZOzGhY3K86)
#### ----> [SVM - Kernel Trick](https://youtu.be/OKFMZQyDROI?si=rh6HRvj6212jRXUQ)

### $$ [Decision Trees](https://medium.com/@MrBam44/decision-trees-91f61a42c724)

### $$ [Ensemble Learning](https://medium.com/@sumbatilinda/ensemble-learning-in-machine-learning-bagging-boosting-and-stacking-a00c6bae971f)
#### ---> [Random Forest | Bagging](https://medium.com/@harshdeepsingh_35448/understanding-random-forests-aa0ccecdbbbb)
#### ---> [AdaBoost | Boosting](https://medium.com/@curryrowan/adaboost-explained-92408a6713da)
#### ---> Gradient Boosting Machine(GBM) [Regression](https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b), [Classification](https://www.digitalocean.com/community/tutorials/gradient-boosting-for-classification)
#### ---> [XGBoost](https://medium.com/@prathameshsonawane/xgboost-how-does-this-work-e1cae7c5b6cb)



## $$ Model Evaluation
### ---> [Confusion Matrix](https://medium.com/@nikitamalviya/confusion-matrix-870739a1ec31)
### ---> [ROC - AUC Curve](https://medium.com/@msong507/understanding-the-roc-auc-curve-cc204f0b3441)
### ---> Cross Validation
### ---> Bias - Variance Trade-off


# Unsupervised Learning
### $$ Clustering
#### ---> [K-means Clustering](https://medium.com/@dishantkharkar9/k-means-clustering-algorithm-ce4fbcac8fb0) | [Video to visualise](https://www.youtube.com/watch?v=R2e3Ls9H_fc)
#### ---> [Hierarchical Clustering](https://medium.com/@sachinsoni600517/mastering-hierarchical-clustering-from-basic-to-advanced-5e770260bf93)
#### ---> [Density Based Spatial Clustering of Applications with Noise(DBSCAN)](https://elutins.medium.com/dbscan-what-is-it-when-to-use-it-how-to-use-it-8bd506293818)
#### ---> [Mean Shift](https://medium.com/@kendigo.0416/understanding-patterns-with-mean-shift-clustering-in-medical-image-analysis-b3c91d1a9dae)

### $$ Dimensionality Reduction
#### ---> [PCA](https://medium.com/@aptrishu/understanding-principle-component-analysis-e32be0253ef0)
#### ---> [Kernel PCA](https://medium.com/@khwabkalra1/unleashing-the-power-of-kernel-pca-bce7f4d2923d)
#### ---> [t-SNE (t-distributed Stochastic Neighbour Embedding)](https://medium.com/@sachinsoni600517/mastering-t-sne-t-distributed-stochastic-neighbor-embedding-0e365ee898ea)
#### ---> [Linear Discriminant Analysis](https://medium.com/@gajendra.k.s/linear-discriminant-analysis-lda-8b8d0c163e08)
#### ---> [Auto Encoders](https://medium.com/game-of-bits/what-are-autoencoders-in-deep-learning-ba802298bc70)
### $$ Anomaly Detection
#### ---> [Isolation Forest](https://medium.com/@corymaklin/isolation-forest-799fceacdda4)
### $$ Association Rule Learning
### $$ Other Techniques


## $$ Missing Data Handling
### ---> Simple Imputation (Mean, Median, Mode)
#### ---> [KNN Imputation](https://medium.com/@kyawsawhtoon/a-guide-to-knn-imputation-95e2dc496e)
### ---> Random Forest Imputation [A different Smart approach](https://medium.com/analytics-vidhya/smart-data-imputation-using-random-forest-58a9aedd557a)
### ---> [Multivariate Imputation by Chained Equation (MICE)](https://medium.com/@kunalshrm175/multivariate-imputation-by-chained-equations-mice-2d3efb063434#:~:text=The%20MICE%20algorithm%20is%20a,restoring%20completeness%20for%20comprehensive%20analysis.)
### ---> Deletion/Ignoring Mission Values
### ---> Expectation-Maximization (EM) Algorithm
### ---> Auto-Encoder Based Imputation (Specifically for Deep Learning or AI Research Roles)

